{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_From_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUt2iItfmzvd",
        "colab_type": "text"
      },
      "source": [
        "** This programme is from scratch on Convolutional neural networks(CNN)**\n",
        "\n",
        "*   First we will gonna import libraries like numpy,gzip,tqdm,pickle\n",
        "*   After that we will see how convlutional Neural Network Works on MNIST handwriting dataset\n",
        "\n",
        "Why we are importing these libraries ?\n",
        "Answer is simple libraries are used to handle the data in a way to train CNN.Below are some libraries which i have used in this project\n",
        "\n",
        "--> **Numpy** - This is imported because for handling , reading images,arrays (multidimensions)\n",
        "            and to do some operations on matrices and many more.To know more check \n",
        "            out documentation https://numpy.org/doc/\n",
        "\n",
        "--> **gzip** - This library is imported to handle gzip files .To know about this check out the documentation https://docs.python.org/3/library/gzip.html\n",
        "\n",
        "--> **tqdm** - This is basically used to represent how iteration are working like a meter .To get it in a more good way just visit https://tqdm.github.io/\n",
        "\n",
        "--> **pickle** - This library is imported to save the trained CNN programme files in a pickle file with binary format .To know about it https://wiki.python.org/moin/UsingPickle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZTk5fM5mwiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "from tqdm import tqdm   \n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YficQDYmrqh8",
        "colab_type": "text"
      },
      "source": [
        "**Below is the program of Convolution operation**\n",
        "\n",
        "Let's see how convolution operation works in CNN\n",
        "\n",
        "**What is convolution?**\n",
        "\n",
        "In purely mathematical terms, convolution is a function derived from two given functions by integration which expresses how the shape of one is modified by the other. That can sound baffling as it is, but to make matters worse, we can take a look at the convolution formula:\n",
        "\n",
        "![alt text](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/70_blog_image_1.png)\n",
        "\n",
        "If you who have practiced any field that entails signal processing are probably familiar with the convolution function.\n",
        "\n",
        "Let's get into the actual convolution operation in the context of neural networks. The following example will provide you with a breakdown of everything you need to know about this process.\n",
        "\n",
        "![alt text](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/70_blog_image_2.png)\n",
        "\n",
        "**How exactly does the Convolution Operation work?**\n",
        "\n",
        "You can think of the feature detector(filter) as a window consisting of 9 (3×3) cells. Here is what you do with it:\n",
        "\n",
        "--> You place it over the input image beginning from the top-left corner within the borders you see demarcated above, and then you count the number of cells in which the feature detector matches the input image.\n",
        "\n",
        "--> The number of matching cells is then inserted in the top-left cell of the feature map.\n",
        "\n",
        "--> You then move the feature detector one cell to the right and do the same thing. This movement is called a and since we are moving the feature detector one cell at time, that would be called a stride of one pixel.\n",
        "\n",
        "--> What you will find in this example is that the feature detector's middle-left cell with the number 1 inside it matches the cell that it is standing over inside the input image. That's the only matching cell, and so you write “1” in the next cell in the feature map, and so on and so forth.\n",
        "\n",
        "--> After you have gone through the whole first row, you can then move it over to the next row and go through the same process.\n",
        "\n",
        "It's important not to confuse the feature map with the other two elements. The cells of the feature map can contain any digit, not only 1's and 0's. After going over every pixel in the input image in the example above, we would end up with these results:\n",
        "\n",
        "![alt text](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/70_blog_image_3.png)\n",
        "\n",
        "![alt text](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/70_blog_image_4.png)\n",
        "\n",
        "To get Convolution in a more clear way see the image below and animation:\n",
        "![alt text](https://qphs.fs.quoracdn.net/main-qimg-7800235ab45a17e12b0ba7fc74572a9c)\n",
        "\n",
        "![alt text](https://miro.medium.com/max/535/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif)\n",
        "\n",
        "![alt text](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-05-at-11-03-00-pm.png?w=342&h=562)\n",
        "\n",
        "By the way, just like feature detector can also be referred to as a kernel or a filter, a feature map is also known as an activation map and both terms are also interchangeable.\n",
        "\n",
        "To Know more about this follow the link https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AubiExhAx6EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolution(image, filt, bias, s=1):\n",
        "    '''\n",
        "    Confolves `filt` over `image` using stride `s`\n",
        "    '''\n",
        "    (n_f, n_c_f, f, _) = filt.shape # filter dimensions\n",
        "    n_c, in_dim, _ = image.shape # image dimensions\n",
        "    \n",
        "    out_dim = int((in_dim - f)/s)+1 # calculate output dimensions\n",
        "    \n",
        "    # ensure that the filter dimensions match the dimensions of the input image\n",
        "    assert n_c == n_c_f, \"Dimensions of filter must match dimensions of input image\"\n",
        "    \n",
        "    out = np.zeros((n_f,out_dim,out_dim)) # create the matrix to hold the values of the convolution operation\n",
        "    \n",
        "    # convolve each filter over the image\n",
        "    for curr_f in range(n_f):\n",
        "        curr_y = out_y = 0\n",
        "        # move filter vertically across the image\n",
        "        while curr_y + f <= in_dim:\n",
        "            curr_x = out_x = 0\n",
        "            # move filter horizontally across the image \n",
        "            while curr_x + f <= in_dim:\n",
        "                # perform the convolution operation and add the bias\n",
        "                out[curr_f, out_y, out_x] = np.sum(filt[curr_f] * image[:,curr_y:curr_y+f, curr_x:curr_x+f]) + bias[curr_f]\n",
        "                curr_x += s\n",
        "                out_x += 1\n",
        "            curr_y += s\n",
        "            out_y += 1\n",
        "        \n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY1a2dxOwzsS",
        "colab_type": "text"
      },
      "source": [
        "Below is the implementaion of Maxpooling\n",
        "\n",
        "**Now let's see how maxpooling works in CNN**\n",
        "\n",
        "**Max pooling** is a sample-based discretization process. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.\n",
        "\n",
        "This is done to in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn and provides basic translation invariance to the internal representation.\n",
        "\n",
        "**Max pooling** is done by applying a max filter to (usually) non-overlapping subregions of the initial representation.\n",
        "\n",
        "Let's say we have a 4x4 matrix representing our initial input.\n",
        "Let's say, as well, that we have a 2x2 filter that we'll run over our input. We'll have a stride of 2 (meaning the (dx, dy) for stepping over our input will be (2, 2)) and won't overlap regions.\n",
        "\n",
        "For each of the regions represented by the filter, we will take the max of that region and create a new, output matrix where each element is the max of a region in the original input.\n",
        "\n",
        "In order to make this super easy, with a nice pictorial representation - I give you this:\n",
        "\n",
        "![alt text](https://qphs.fs.quoracdn.net/main-qimg-8afedfb2f82f279781bfefa269bc6a90.webp)\n",
        "\n",
        "For a real example (note that the z dimension, the number of layers, remains unchanged in the pooling operation):\n",
        "\n",
        "![alt text](https://qphs.fs.quoracdn.net/main-qimg-3a8a3a78734fed3301ed3546634b871a.webp)\n",
        "\n",
        "![alt text](https://qphs.fs.quoracdn.net/main-qimg-3a8a3a78734fed3301ed3546634b871a.webp)\n",
        "\n",
        "![alt text](https://qphs.fs.quoracdn.net/main-qimg-40cdeb3b43594f4b1b1b6e2c137e80b7.webp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iVJ5y06z0GF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Max pool which is used to reduce the dimension of the image to get important features\n",
        "\n",
        "def maxpool(image,SizeofPool,stride):\n",
        "\n",
        "  #Size of pool is nothing but the window size of the matrix \n",
        "\n",
        "  (NoOFChannels,ImgHeight,ImgWidth) = image.shape                               #Image Shape is returned\n",
        "  \n",
        "  #Image Size after pooling of the image matrix \n",
        "  OutHeight = int((ImgHeight-SizeofPool)/stride)+1\n",
        "  OutWidth = int((ImgWidth-SizeofPool)/stride)+1\n",
        "\n",
        "  #Create output downsampled(Reduced Size of the Image) matrix \n",
        "  Downsample = np.zeros((NoOFChannels,OutHeight,OutWidth))\n",
        "\n",
        "  # Matrix of Size(SizeofPool) slides over the input image and get the max value out of it...\n",
        "  for channels in range(NoOFChannels):\n",
        "\n",
        "    PoolHght = out_hght = 0\n",
        "    while PoolHght+SizeofPool <= ImgHeight:                                     #Sliding vertically over the image\n",
        "\n",
        "      PoolWdth = out_wdth = 0\n",
        "      while PoolWdth+SizeofPool <= ImgWidth:                                    #Sliding horizontally over the image\n",
        "\n",
        "        Downsample[channels,out_hght,out_wdth] = np.max(image[channels,PoolHght:PoolHght+SizeofPool,PoolWdth:PoolWdth+SizeofPool])\n",
        "        out_wdth += 1\n",
        "        PoolWdth += stride\n",
        "\n",
        "      out_hght += 1\n",
        "      PoolHght +=stride\n",
        "\n",
        "  return Downsample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr_BWjBszbgg",
        "colab_type": "text"
      },
      "source": [
        "Below is the program to extract images and labels for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRiP1fBFXNls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
        "    '''\n",
        "    Extract images by reading the file bytestream. Reshape the read values into a 3D matrix of dimensions [m, h, w], where m \n",
        "    is the number of training examples.\n",
        "    '''\n",
        "    print('Extracting', filename)\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        data = bytestream.read(16)\n",
        "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
        "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
        "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
        "        return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_P3i_hsXiGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_labels(filename, num_images):\n",
        "    '''\n",
        "    Extract label into vector of integer values of dimensions [m, 1], where m is the number of images.\n",
        "    '''\n",
        "    print('Extracting', filename)\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        labels = bytestream.read(8)\n",
        "        buf = bytestream.read(1 * num_images)\n",
        "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roCacY2IzqWP",
        "colab_type": "text"
      },
      "source": [
        "**initializeFilter function** ----> is used to initialize filter values randomly .\n",
        "\n",
        "Similarly,\n",
        "\n",
        "**initializeWeight function** ----> is used to initialize weights when layers are flatten(you will get it to know later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4HsdwMCXoW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def initializeFilter(size, scale = 1.0):\n",
        "    '''\n",
        "    Initialize filter using a normal distribution with and a \n",
        "    standard deviation inversely proportional the square root of the number of units\n",
        "    '''\n",
        "    stddev = scale/np.sqrt(np.prod(size))\n",
        "    return np.random.normal(loc = 0, scale = stddev, size = size)\n",
        "\n",
        "def initializeWeight(size):\n",
        "    '''\n",
        "    Initialize weights with a random normal distribution\n",
        "    '''\n",
        "    return np.random.standard_normal(size=size) * 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S6i_Vjp0Ze-",
        "colab_type": "text"
      },
      "source": [
        "**Below is the program based on cross entropy loss function :**\n",
        "\n",
        "Cross Entropy loss can be represented as :\n",
        "\n",
        "![alt text](https://miro.medium.com/max/652/1*37E--HHncb5icJg5xI7drw.png)\n",
        "\n",
        "To know more follow the link:\n",
        "\n",
        "https://medium.com/data-science-bootcamp/understand-cross-entropy-loss-in-minutes-9fb263caee9a\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZdfbZlNdygZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def categoricalCrossEntropy(probs, label):\n",
        "    '''\n",
        "    calculate the categorical cross-entropy loss of the predictions\n",
        "    '''\n",
        "    return -np.sum(label * np.log(probs)) # Multiply the desired output label by the log of the prediction, then sum all values in the vector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP6feSul2ITW",
        "colab_type": "text"
      },
      "source": [
        "**Below is the program on Softmax**\n",
        "\n",
        "Softmax is used to get the output in between 0 and 1 \n",
        "\n",
        "To know more about it follow the link \n",
        "\n",
        "https://en.wikipedia.org/wiki/Softmax_function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA-ES6bPyG_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(preds):\n",
        "  '''\n",
        "    passing predictions through the softmax prediction function\n",
        "  '''\n",
        "  out = np.exp(preds)\n",
        "  return out/np.sum(out) #divide the exponential vector by its sum to get the values between 0 and 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LyuJIkQ5wmI",
        "colab_type": "text"
      },
      "source": [
        "**Below code of convolutionBackward and maxpoolBackward are nothing but the part of backpropagation in CNN**\n",
        "\n",
        "This is explained here:\n",
        "\n",
        "https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-8esppuM1eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convolutionBackward(dconv_prev, conv_in, filt, s):\n",
        "    '''\n",
        "    Backpropagation through a convolutional layer. \n",
        "    '''\n",
        "    (n_f, n_c, f, _) = filt.shape\n",
        "    (_, orig_dim, _) = conv_in.shape\n",
        "    ## initialize derivatives\n",
        "    dout = np.zeros(conv_in.shape) \n",
        "    dfilt = np.zeros(filt.shape)\n",
        "    dbias = np.zeros((n_f,1))\n",
        "    for curr_f in range(n_f):\n",
        "        # loop through all filters\n",
        "        curr_y = out_y = 0\n",
        "        while curr_y + f <= orig_dim:\n",
        "            curr_x = out_x = 0\n",
        "            while curr_x + f <= orig_dim:\n",
        "                # loss gradient of filter (used to update the filter)\n",
        "                dfilt[curr_f] += dconv_prev[curr_f, out_y, out_x] * conv_in[:, curr_y:curr_y+f, curr_x:curr_x+f]\n",
        "                # loss gradient of the input to the convolution operation (conv1 in the case of this network)\n",
        "                dout[:, curr_y:curr_y+f, curr_x:curr_x+f] += dconv_prev[curr_f, out_y, out_x] * filt[curr_f] \n",
        "                curr_x += s\n",
        "                out_x += 1\n",
        "            curr_y += s\n",
        "            out_y += 1\n",
        "        # loss gradient of the bias\n",
        "        dbias[curr_f] = np.sum(dconv_prev[curr_f])\n",
        "    \n",
        "    return dout, dfilt, dbias\n",
        "\n",
        "def nanargmax(arr):\n",
        "    '''\n",
        "    return index of the largest non-nan value in the array. Output is an ordered pair tuple\n",
        "    '''\n",
        "    idx = np.nanargmax(arr)\n",
        "    idxs = np.unravel_index(idx, arr.shape)\n",
        "    return idxs \n",
        "\n",
        "def maxpoolBackward(dpool, orig, f, s):\n",
        "    '''\n",
        "    Backpropagation through a maxpooling layer. The gradients are passed through the indices of greatest value in the original maxpooling during the forward step.\n",
        "    '''\n",
        "    (n_c, orig_dim, _) = orig.shape\n",
        "    \n",
        "    dout = np.zeros(orig.shape)\n",
        "    \n",
        "    for curr_c in range(n_c):\n",
        "        curr_y = out_y = 0\n",
        "        while curr_y + f <= orig_dim:\n",
        "            curr_x = out_x = 0\n",
        "            while curr_x + f <= orig_dim:\n",
        "                # obtain index of largest value in input for current window\n",
        "                (a, b) = nanargmax(orig[curr_c, curr_y:curr_y+f, curr_x:curr_x+f])\n",
        "                dout[curr_c, curr_y+a, curr_x+b] = dpool[curr_c, out_y, out_x]\n",
        "                \n",
        "                curr_x += s\n",
        "                out_x += 1\n",
        "            curr_y += s\n",
        "            out_y += 1\n",
        "        \n",
        "    return dout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blITDg5w6pZu",
        "colab_type": "text"
      },
      "source": [
        "conv function is used to combine operations of convolution and maxpooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Wa2bpZoHNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def conv(image, label, params, conv_s, pool_f, pool_s):\n",
        "    \n",
        "    [f1, f2, w3, w4, b1, b2, b3, b4] = params \n",
        "    \n",
        "    ################################################\n",
        "    ############## Forward Operation ###############\n",
        "    ################################################\n",
        "    conv1 = convolution(image, f1, b1, conv_s) # convolution operation\n",
        "    conv1[conv1<=0] = 0 # pass through ReLU non-linearity\n",
        "    \n",
        "    conv2 = convolution(conv1, f2, b2, conv_s) # second convolution operation\n",
        "    conv2[conv2<=0] = 0 # pass through ReLU non-linearity\n",
        "    \n",
        "    pooled = maxpool(conv2, pool_f, pool_s) # maxpooling operation\n",
        "    \n",
        "    (nf2, dim2, _) = pooled.shape\n",
        "    fc = pooled.reshape((nf2 * dim2 * dim2, 1)) # flatten pooled layer\n",
        "    \n",
        "    z = w3.dot(fc) + b3 # first dense layer\n",
        "    z[z<=0] = 0 # pass through ReLU non-linearity\n",
        "    \n",
        "    out = w4.dot(z) + b4 # second dense layer\n",
        "     \n",
        "    probs = softmax(out) # predict class probabilities with the softmax activation function\n",
        "    \n",
        "    ################################################\n",
        "    #################### Loss ######################\n",
        "    ################################################\n",
        "    \n",
        "    loss = categoricalCrossEntropy(probs, label) # categorical cross-entropy loss\n",
        "        \n",
        "    ################################################\n",
        "    ############# Backward Operation ###############\n",
        "    ################################################\n",
        "    dout = probs - label # derivative of loss w.r.t. final dense layer output\n",
        "    dw4 = dout.dot(z.T) # loss gradient of final dense layer weights\n",
        "    db4 = np.sum(dout, axis = 1).reshape(b4.shape) # loss gradient of final dense layer biases\n",
        "    \n",
        "    dz = w4.T.dot(dout) # loss gradient of first dense layer outputs \n",
        "    dz[z<=0] = 0 # backpropagate through ReLU \n",
        "    dw3 = dz.dot(fc.T)\n",
        "    db3 = np.sum(dz, axis = 1).reshape(b3.shape)\n",
        "    \n",
        "    dfc = w3.T.dot(dz) # loss gradients of fully-connected layer (pooling layer)\n",
        "    dpool = dfc.reshape(pooled.shape) # reshape fully connected into dimensions of pooling layer\n",
        "    \n",
        "    dconv2 = maxpoolBackward(dpool, conv2, pool_f, pool_s) # backprop through the max-pooling layer(only neurons with highest activation in window get updated)\n",
        "    dconv2[conv2<=0] = 0 # backpropagate through ReLU\n",
        "    \n",
        "    dconv1, df2, db2 = convolutionBackward(dconv2, conv1, f2, conv_s) # backpropagate previous gradient through second convolutional layer.\n",
        "    dconv1[conv1<=0] = 0 # backpropagate through ReLU\n",
        "    \n",
        "    dimage, df1, db1 = convolutionBackward(dconv1, image, f1, conv_s) # backpropagate previous gradient through first convolutional layer.\n",
        "    \n",
        "    grads = [df1, df2, dw3, dw4, db1, db2, db3, db4] \n",
        "    \n",
        "    return grads, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYmfTvL07FSF",
        "colab_type": "text"
      },
      "source": [
        "**Adam Gradient** is one of the best optimizer till now  which uses process of momentum and RMSProp\n",
        "\n",
        "This can be explained here\n",
        "\n",
        "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDKpUIrqoPuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def adamGD(batch, num_classes, lr, dim, n_c, beta1, beta2, params, cost):\n",
        "    '''\n",
        "    update the parameters through Adam gradient descnet.\n",
        "    '''\n",
        "    [f1, f2, w3, w4, b1, b2, b3, b4] = params\n",
        "    \n",
        "    X = batch[:,0:-1] # get batch inputs\n",
        "    X = X.reshape(len(batch), n_c, dim, dim)\n",
        "    Y = batch[:,-1] # get batch labels\n",
        "    \n",
        "    cost_ = 0\n",
        "    batch_size = len(batch)\n",
        "    \n",
        "    # initialize gradients and momentum,RMS params\n",
        "    df1 = np.zeros(f1.shape)\n",
        "    df2 = np.zeros(f2.shape)\n",
        "    dw3 = np.zeros(w3.shape)\n",
        "    dw4 = np.zeros(w4.shape)\n",
        "    db1 = np.zeros(b1.shape)\n",
        "    db2 = np.zeros(b2.shape)\n",
        "    db3 = np.zeros(b3.shape)\n",
        "    db4 = np.zeros(b4.shape)\n",
        "    \n",
        "    v1 = np.zeros(f1.shape)\n",
        "    v2 = np.zeros(f2.shape)\n",
        "    v3 = np.zeros(w3.shape)\n",
        "    v4 = np.zeros(w4.shape)\n",
        "    bv1 = np.zeros(b1.shape)\n",
        "    bv2 = np.zeros(b2.shape)\n",
        "    bv3 = np.zeros(b3.shape)\n",
        "    bv4 = np.zeros(b4.shape)\n",
        "    \n",
        "    s1 = np.zeros(f1.shape)\n",
        "    s2 = np.zeros(f2.shape)\n",
        "    s3 = np.zeros(w3.shape)\n",
        "    s4 = np.zeros(w4.shape)\n",
        "    bs1 = np.zeros(b1.shape)\n",
        "    bs2 = np.zeros(b2.shape)\n",
        "    bs3 = np.zeros(b3.shape)\n",
        "    bs4 = np.zeros(b4.shape)\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        x = X[i]\n",
        "        y = np.eye(num_classes)[int(Y[i])].reshape(num_classes, 1) # convert label to one-hot\n",
        "        \n",
        "        # Collect Gradients for training example\n",
        "        grads, loss = conv(x, y, params, 1, 2, 2)\n",
        "        [df1_, df2_, dw3_, dw4_, db1_, db2_, db3_, db4_] = grads\n",
        "        \n",
        "        df1+=df1_\n",
        "        db1+=db1_\n",
        "        df2+=df2_\n",
        "        db2+=db2_\n",
        "        dw3+=dw3_\n",
        "        db3+=db3_\n",
        "        dw4+=dw4_\n",
        "        db4+=db4_\n",
        "\n",
        "        cost_+= loss\n",
        "\n",
        "    # Parameter Update  \n",
        "        \n",
        "    v1 = beta1*v1 + (1-beta1)*df1/batch_size # momentum update\n",
        "    s1 = beta2*s1 + (1-beta2)*(df1/batch_size)**2 # RMSProp update\n",
        "    f1 -= lr * v1/np.sqrt(s1+1e-7) # combine momentum and RMSProp to perform update with Adam\n",
        "    \n",
        "    bv1 = beta1*bv1 + (1-beta1)*db1/batch_size\n",
        "    bs1 = beta2*bs1 + (1-beta2)*(db1/batch_size)**2\n",
        "    b1 -= lr * bv1/np.sqrt(bs1+1e-7)\n",
        "   \n",
        "    v2 = beta1*v2 + (1-beta1)*df2/batch_size\n",
        "    s2 = beta2*s2 + (1-beta2)*(df2/batch_size)**2\n",
        "    f2 -= lr * v2/np.sqrt(s2+1e-7)\n",
        "                       \n",
        "    bv2 = beta1*bv2 + (1-beta1) * db2/batch_size\n",
        "    bs2 = beta2*bs2 + (1-beta2)*(db2/batch_size)**2\n",
        "    b2 -= lr * bv2/np.sqrt(bs2+1e-7)\n",
        "    \n",
        "    v3 = beta1*v3 + (1-beta1) * dw3/batch_size\n",
        "    s3 = beta2*s3 + (1-beta2)*(dw3/batch_size)**2\n",
        "    w3 -= lr * v3/np.sqrt(s3+1e-7)\n",
        "    \n",
        "    bv3 = beta1*bv3 + (1-beta1) * db3/batch_size\n",
        "    bs3 = beta2*bs3 + (1-beta2)*(db3/batch_size)**2\n",
        "    b3 -= lr * bv3/np.sqrt(bs3+1e-7)\n",
        "    \n",
        "    v4 = beta1*v4 + (1-beta1) * dw4/batch_size\n",
        "    s4 = beta2*s4 + (1-beta2)*(dw4/batch_size)**2\n",
        "    w4 -= lr * v4 / np.sqrt(s4+1e-7)\n",
        "    \n",
        "    bv4 = beta1*bv4 + (1-beta1)*db4/batch_size\n",
        "    bs4 = beta2*bs4 + (1-beta2)*(db4/batch_size)**2\n",
        "    b4 -= lr * bv4 / np.sqrt(bs4+1e-7)\n",
        "    \n",
        "\n",
        "    cost_ = cost_/batch_size\n",
        "    cost.append(cost_)\n",
        "\n",
        "    params = [f1, f2, w3, w4, b1, b2, b3, b4]\n",
        "    \n",
        "    return params, cost\n",
        "\n",
        "#####################################################\n",
        "##################### Training ######################\n",
        "#####################################################\n",
        "\n",
        "def train(num_classes = 10, lr = 0.01, beta1 = 0.95, beta2 = 0.99, img_dim = 28, img_depth = 1, f = 5, num_filt1 = 8, num_filt2 = 8, batch_size = 32, num_epochs = 2, save_path = 'params.pkl'):\n",
        "\n",
        "    # Get training data\n",
        "    m =50000\n",
        "    X = extract_data('train-images-idx3-ubyte.gz', m, img_dim)\n",
        "    y_dash = extract_labels('train-labels-idx1-ubyte.gz', m).reshape(m,1)\n",
        "    X-= int(np.mean(X))\n",
        "    X/= int(np.std(X))\n",
        "    train_data = np.hstack((X,y_dash))\n",
        "\n",
        "    np.random.shuffle(train_data)\n",
        "\n",
        "    ## Initializing all the parameters\n",
        "    f1, f2, w3, w4 = (num_filt1 ,img_depth,f,f), (num_filt2 ,num_filt1,f,f), (128,800), (10, 128)\n",
        "    f1 = initializeFilter(f1)\n",
        "    f2 = initializeFilter(f2)\n",
        "    w3 = initializeWeight(w3)\n",
        "    w4 = initializeWeight(w4)\n",
        "\n",
        "    b1 = np.zeros((f1.shape[0],1))\n",
        "    b2 = np.zeros((f2.shape[0],1))\n",
        "    b3 = np.zeros((w3.shape[0],1))\n",
        "    b4 = np.zeros((w4.shape[0],1))\n",
        "\n",
        "    params = [f1, f2, w3, w4, b1, b2, b3, b4]\n",
        "\n",
        "    cost = []\n",
        "\n",
        "    print(\"LR:\"+str(lr)+\", Batch Size:\"+str(batch_size))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        np.random.shuffle(train_data)\n",
        "        batches = [train_data[k:k + batch_size] for k in range(0, train_data.shape[0], batch_size)]\n",
        "\n",
        "        t = tqdm(batches)\n",
        "        for x,batch in enumerate(t):\n",
        "            params, cost = adamGD(batch, num_classes, lr, img_dim, img_depth, beta1, beta2, params, cost)\n",
        "            t.set_description(\"Cost: %.2f\" % (cost[-1]))\n",
        "            \n",
        "\n",
        "    with open(save_path, 'wb') as file:\n",
        "        pickle.dump(params, file)\n",
        "        \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}